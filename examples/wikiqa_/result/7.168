Namespace(MP_dim=20, NER_dim=20, POS_dim=20, aggregation_layer_num=1, aggregation_lstm_dim=100, attention_type='bilinear', batch_size=40, char_emb_dim=40, char_lstm_dim=80, context_layer_num=1, context_lstm_dim=50, dev_path='../data/wikiqa/WikiQACorpus/WikiQA-dev.txt', dropout_rate=0.04, fix_word_vec=True, highway_layer_num=1, is_aggregation_lstm=False, is_aggregation_siamese=False, is_answer_selection=True, is_server=True, is_shared_attention=False, lambda_l2=0.0, learning_rate=0.002, lex_decompsition_dim=-1, max_char_per_word=10, max_epochs=10, max_sent_length=100, max_window_size=3, model_dir='../models', modify_loss=0.1, optimize_type='adam', prediction_mode='list_wise', suffix='normal', test_path='../data/wikiqa/WikiQACorpus/WikiQA-test.txt', train_path='../data/wikiqa/WikiQACorpus/WikiQA-train.txt', type1='w_sub_mul', type2='mul', type3='w_sub_mul', unstack_cnn=False, with_NER=False, with_POS=False, with_aggregation_highway=False, with_context_self_attention=True, with_filter_layer=False, with_highway=True, with_lex_decomposition=False, with_match_highway=False, wo_agg_self_att=True, wo_attentive_match=True, wo_char=True, wo_full_match=True, wo_left_match=False, wo_lstm_drop_out=True, wo_max_attentive_match=True, wo_maxpool_match=True, wo_right_match=False, word_level_MP_dim=-1, word_vec_path='../data/glove/glove.6B.50d.txt')

Step 272: loss = 953.29 (64.072 sec)
valid- map: '0.570639971434', mrr: '0.578791688911'
test- map: '0.545121519427', mrr: '0.553246901704

Step 545: loss = 889.99 (72.550 sec)
valid- map: '0.602649544019', mrr: '0.608596914549'
test- map: '0.575099620268', mrr: '0.57857193701

Step 818: loss = 837.35 (71.410 sec)
valid- map: '0.594823749883', mrr: '0.600229422253'
test- map: '0.574956792897', mrr: '0.583031261329

Step 1091: loss = 833.71 (72.004 sec)
valid- map: '0.619273869437', mrr: '0.625768712043'
test- map: '0.579974853394', mrr: '0.589065948531

Step 1364: loss = 815.01 (72.316 sec)
valid- map: '0.618285264119', mrr: '0.620738366572'
test- map: '0.599043434432', mrr: '0.607836195583

Step 1637: loss = 806.58 (71.580 sec)
valid- map: '0.608343603348', mrr: '0.614029643196'
test- map: '0.579324741478', mrr: '0.589099846199

Step 1910: loss = 829.07 (71.698 sec)
valid- map: '0.615592776867', mrr: '0.623806917224'
test- map: '0.570285598931', mrr: '0.578359498478

Step 2183: loss = 755.62 (71.304 sec)
valid- map: '0.595557282958', mrr: '0.598737660047'
test- map: '0.579694782745', mrr: '0.586540642713

Step 2456: loss = 748.04 (72.099 sec)
valid- map: '0.573544011838', mrr: '0.579891118582'
test- map: '0.577053602704', mrr: '0.585387828906

Step 2729: loss = 753.98 (71.916 sec)
valid- map: '0.61312543195', mrr: '0.612419678268'
test- map: '0.60526170584', mrr: '0.618890140754

train- map: '0.608570645521', mrr: '0.623596718437'
