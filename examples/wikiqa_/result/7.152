Namespace(MP_dim=20, NER_dim=20, POS_dim=20, aggregation_layer_num=1, aggregation_lstm_dim=100, attention_type='bilinear', batch_size=40, char_emb_dim=40, char_lstm_dim=80, context_layer_num=1, context_lstm_dim=50, dev_path='../data/wikiqa/WikiQACorpus/WikiQA-dev.txt', dropout_rate=0.04, fix_word_vec=True, highway_layer_num=1, is_aggregation_lstm=False, is_aggregation_siamese=False, is_answer_selection=True, is_server=True, is_shared_attention=False, lambda_l2=0.0, learning_rate=0.002, lex_decompsition_dim=-1, max_char_per_word=10, max_epochs=10, max_sent_length=100, max_window_size=3, model_dir='../models', modify_loss=0.1, optimize_type='adam', prediction_mode='list_wise', suffix='normal', test_path='../data/wikiqa/WikiQACorpus/WikiQA-test.txt', train_path='../data/wikiqa/WikiQACorpus/WikiQA-train.txt', type1='w_sub_mul', type2='mul', type3='w_sub_mul', unstack_cnn=False, with_NER=False, with_POS=False, with_aggregation_highway=False, with_context_self_attention=True, with_filter_layer=False, with_highway=False, with_lex_decomposition=False, with_match_highway=False, wo_agg_self_att=True, wo_attentive_match=True, wo_char=True, wo_full_match=True, wo_left_match=False, wo_lstm_drop_out=True, wo_max_attentive_match=True, wo_maxpool_match=True, wo_right_match=False, word_level_MP_dim=-1, word_vec_path='../data/glove/glove.6B.50d.txt')

Step 272: loss = 943.89 (63.259 sec)
valid- map: '0.571052345269', mrr: '0.572583816443'
test- map: '0.575710693426', mrr: '0.584310061761

Step 545: loss = 895.33 (70.730 sec)
valid- map: '0.60318176092', mrr: '0.605512322774'
test- map: '0.566279851025', mrr: '0.575067802076

Step 818: loss = 886.27 (70.996 sec)
valid- map: '0.61895370943', mrr: '0.629866407843'
test- map: '0.592332945131', mrr: '0.600355186949

Step 1091: loss = 791.44 (70.202 sec)
valid- map: '0.621790276155', mrr: '0.623936072746'
test- map: '0.607945747202', mrr: '0.620013213028

Step 1364: loss = 676.99 (70.793 sec)
valid- map: '0.662180096505', mrr: '0.665082800797'
test- map: '0.629612830732', mrr: '0.64005654839

Step 1637: loss = 616.83 (69.511 sec)
valid- map: '0.655373876912', mrr: '0.659957840127'
test- map: '0.625918516929', mrr: '0.636532997181

Step 1910: loss = 520.42 (69.358 sec)
valid- map: '0.693063715385', mrr: '0.696072688335'
test- map: '0.627085252181', mrr: '0.634879005849

Step 2183: loss = 450.74 (70.273 sec)
valid- map: '0.662440366646', mrr: '0.663156856946'
test- map: '0.661418297318', mrr: '0.670148724161

Step 2456: loss = 390.49 (70.144 sec)
valid- map: '0.667065066767', mrr: '0.668754724112'
test- map: '0.650856278234', mrr: '0.660026187804

Step 2729: loss = 338.27 (69.456 sec)
valid- map: '0.702651316937', mrr: '0.70559443863'
test- map: '0.655329178994', mrr: '0.662713007157

train- map: '0.868260544525', mrr: '0.879916494349'
