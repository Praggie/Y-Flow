Namespace(MP_dim=20, NER_dim=20, POS_dim=20, aggregation_layer_num=1, aggregation_lstm_dim=100, attention_type='bilinear', batch_size=40, char_emb_dim=40, char_lstm_dim=80, context_layer_num=1, context_lstm_dim=50, dev_path='../data/wikiqa/WikiQACorpus/WikiQA-dev.txt', dropout_rate=0.04, fix_word_vec=True, highway_layer_num=1, is_aggregation_lstm=False, is_aggregation_siamese=False, is_answer_selection=True, is_server=True, is_shared_attention=False, lambda_l2=0.0, learning_rate=0.002, lex_decompsition_dim=-1, max_char_per_word=10, max_epochs=10, max_sent_length=100, max_window_size=3, model_dir='../models', modify_loss=0.1, optimize_type='adam', prediction_mode='list_wise', suffix='normal', test_path='../data/wikiqa/WikiQACorpus/WikiQA-test.txt', train_path='../data/wikiqa/WikiQACorpus/WikiQA-train.txt', type1='w_sub_mul', type2='mul', type3='w_sub_mul', unstack_cnn=False, with_NER=False, with_POS=False, with_aggregation_highway=False, with_context_self_attention=True, with_filter_layer=False, with_highway=True, with_lex_decomposition=False, with_match_highway=False, wo_agg_self_att=True, wo_attentive_match=True, wo_char=True, wo_full_match=True, wo_left_match=False, wo_lstm_drop_out=True, wo_max_attentive_match=True, wo_maxpool_match=True, wo_right_match=False, word_level_MP_dim=-1, word_vec_path='../data/glove/glove.6B.50d.txt')

Step 272: loss = 908.29 (68.337 sec)
valid- map: '0.60385520197', mrr: '0.609126499603'
test- map: '0.565021318693', mrr: '0.574191722108

Step 545: loss = 899.08 (75.647 sec)
valid- map: '0.620891685475', mrr: '0.625554383888'
test- map: '0.573455316667', mrr: '0.579780836745

Step 818: loss = 849.96 (74.805 sec)
valid- map: '0.643063429075', mrr: '0.649851977828'
test- map: '0.60092251807', mrr: '0.608883470571

Step 1091: loss = 802.70 (74.827 sec)
valid- map: '0.616438334593', mrr: '0.624886621315'
test- map: '0.626404572793', mrr: '0.638304950651

Step 1364: loss = 954.55 (74.625 sec)
valid- map: '0.621203675073', mrr: '0.628637852447'
test- map: '0.613616071075', mrr: '0.621848972929

Step 1637: loss = 831.08 (75.891 sec)
valid- map: '0.637886375089', mrr: '0.645811573788'
test- map: '0.619641623384', mrr: '0.626869586746

Step 1910: loss = 794.62 (74.852 sec)
valid- map: '0.642319405315', mrr: '0.641547275476'
test- map: '0.639543016406', mrr: '0.648495426793

Step 2183: loss = 792.23 (75.299 sec)
valid- map: '0.606146961504', mrr: '0.609586114943'
test- map: '0.590874714071', mrr: '0.601328908939

Step 2456: loss = 734.15 (75.064 sec)
valid- map: '0.65058106576', mrr: '0.650239355001'
test- map: '0.617826631463', mrr: '0.627123702705

Step 2729: loss = 725.72 (74.858 sec)
valid- map: '0.612288791455', mrr: '0.614055609294'
test- map: '0.592562659404', mrr: '0.599057915107

train- map: '0.639522065927', mrr: '0.651989890897'
