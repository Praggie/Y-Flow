Namespace(MP_dim=20, NER_dim=20, POS_dim=20, aggregation_layer_num=1, aggregation_lstm_dim=100, attention_type='bilinear', batch_size=40, char_emb_dim=40, char_lstm_dim=80, context_layer_num=1, context_lstm_dim=50, dev_path='../data/wikiqa/WikiQACorpus/WikiQA-dev.txt', dropout_rate=0.04, fix_word_vec=True, highway_layer_num=1, is_aggregation_lstm=False, is_aggregation_siamese=False, is_answer_selection=True, is_server=True, is_shared_attention=True, lambda_l2=0.0, learning_rate=0.002, lex_decompsition_dim=-1, max_char_per_word=10, max_epochs=10, max_sent_length=100, max_window_size=3, model_dir='../models', modify_loss=0.1, optimize_type='adam', prediction_mode='list_wise', suffix='normal', test_path='../data/wikiqa/WikiQACorpus/WikiQA-test.txt', train_path='../data/wikiqa/WikiQACorpus/WikiQA-train.txt', type1='w_sub_mul', type2='mul', type3='w_sub_mul', unstack_cnn=False, with_NER=False, with_POS=False, with_aggregation_highway=False, with_context_self_attention=True, with_filter_layer=False, with_highway=True, with_lex_decomposition=False, with_match_highway=False, wo_agg_self_att=True, wo_attentive_match=True, wo_char=True, wo_full_match=True, wo_left_match=False, wo_lstm_drop_out=True, wo_max_attentive_match=True, wo_maxpool_match=True, wo_right_match=False, word_level_MP_dim=-1, word_vec_path='../data/glove/glove.6B.50d.txt')

Step 272: loss = 967.19 (66.260 sec)
valid- map: '0.52808416231', mrr: '0.530583217488'
test- map: '0.504941999809', mrr: '0.509222274248

Step 545: loss = 912.59 (73.650 sec)
valid- map: '0.625314749918', mrr: '0.632877241806'
test- map: '0.560519434555', mrr: '0.569084305041

Step 818: loss = 878.56 (73.473 sec)
valid- map: '0.619180705391', mrr: '0.626231704803'
test- map: '0.555426604158', mrr: '0.561073031906

Step 1091: loss = 912.90 (73.615 sec)
valid- map: '0.628203799434', mrr: '0.633814708219'
test- map: '0.585356723848', mrr: '0.598103732653

Step 1364: loss = 858.85 (73.321 sec)
valid- map: '0.640092454417', mrr: '0.648224020248'
test- map: '0.530881022429', mrr: '0.545639800481

Step 1637: loss = 898.07 (72.834 sec)
valid- map: '0.606698107889', mrr: '0.611966781014'
test- map: '0.591214827138', mrr: '0.601186654176

Step 1910: loss = 881.12 (73.096 sec)
valid- map: '0.606151406647', mrr: '0.611382048287'
test- map: '0.57662909104', mrr: '0.585751772771

Step 2183: loss = 960.34 (72.967 sec)
valid- map: '0.524234164487', mrr: '0.531657032625'
test- map: '0.479117108772', mrr: '0.482871217053

Step 2456: loss = 974.14 (73.265 sec)
valid- map: '0.540032347324', mrr: '0.544926527218'
test- map: '0.510909950048', mrr: '0.520285433768

Step 2729: loss = 1036.09 (73.901 sec)
valid- map: '0.572254901758', mrr: '0.579923710022'
test- map: '0.545574699594', mrr: '0.552038319052

train- map: '0.510635180496', mrr: '0.523309613981'
